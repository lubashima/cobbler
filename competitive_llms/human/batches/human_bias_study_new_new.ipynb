{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/minhwalee/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "\n",
    "from itertools import combinations\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa, aggregate_raters\n",
    "import rbo\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path_1 = 'bias_threshold_answer/inputs_1.json'\n",
    "input_path_2 = 'bias_threshold_answer/inputs_2.json'\n",
    "input_path_3 = 'bias_threshold_answer/inputs_3.json'\n",
    "input_path_4 = 'bias_threshold_answer/inputs_4.json'\n",
    "input_path_5 = 'bias_threshold_answer/inputs_5.json'\n",
    "input_path_6 = 'bias_threshold_answer/inputs_6.json'\n",
    "input_path_7 = 'bias_threshold_answer/inputs_7.json'\n",
    "input_path_8 = 'bias_threshold_answer/inputs_8.json'\n",
    "input_path_9 = 'bias_threshold_answer/inputs_9.json'\n",
    "input_path_10 = 'bias_threshold_answer/inputs_10.json'\n",
    "input_path_11 = 'bias_threshold_answer/inputs_11.json'\n",
    "input_path_12 = 'bias_threshold_answer/inputs_12.json'\n",
    "input_path_13 = 'bias_threshold_answer/inputs_13.json'\n",
    "input_path_14 = 'bias_threshold_answer/inputs_14.json'\n",
    "input_path_15 = 'bias_threshold_answer/inputs_15.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_path_1 = 'human_bias/order/real/1.csv'\n",
    "order_path_2 = 'human_bias/order/real/2.csv'\n",
    "order_path_3 = 'human_bias/order/real/3.csv'\n",
    "order_path_4 = 'human_bias/order/real/4.csv'\n",
    "order_path_5 = 'human_bias/order/real/5.csv'\n",
    "order_path_6 = 'human_bias/order/real/6.csv'\n",
    "order_path_7 = 'human_bias/order/real/7.csv'\n",
    "order_path_8 = 'human_bias/order/real/8.csv'\n",
    "order_path_9 = 'human_bias/order/real/9.csv'\n",
    "order_path_10 = 'human_bias/order/real/10.csv'\n",
    "order_path_11 = 'human_bias/order/real/11.csv'\n",
    "order_path_12 = 'human_bias/order/real/12.csv'\n",
    "order_path_13 = 'human_bias/order/real/13.csv'\n",
    "order_path_14 = 'human_bias/order/real/14.csv'\n",
    "order_path_15 = 'human_bias/order/real/15.csv'\n",
    "order_path_16 = 'human_bias/order/real/16.csv'\n",
    "order_path_17 = 'human_bias/order/real/17.csv'\n",
    "order_path_18 = 'human_bias/order/real/18.csv'\n",
    "order_path_19 = 'human_bias/order/real/19.csv'\n",
    "order_path_20 = 'human_bias/order/real/20.csv'\n",
    "order_path_21 = 'human_bias/order/real/21.csv'\n",
    "order_path_22 = 'human_bias/order/real/22.csv'\n",
    "order_path_23 = 'human_bias/order/real/23.csv'\n",
    "order_path_24 = 'human_bias/order/real/24.csv'\n",
    "order_path_25 = 'human_bias/order/real/25.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandwagon_path_1 = 'human_bias/bandwagon/real/1.csv'\n",
    "bandwagon_path_2 = 'human_bias/bandwagon/real/2.csv'\n",
    "bandwagon_path_3 = 'human_bias/bandwagon/real/3.csv'\n",
    "bandwagon_path_4 = 'human_bias/bandwagon/real/4.csv'\n",
    "bandwagon_path_5 = 'human_bias/bandwagon/real/5.csv'\n",
    "bandwagon_path_6 = 'human_bias/bandwagon/real/6.csv'\n",
    "bandwagon_path_7 = 'human_bias/bandwagon/real/7.csv'\n",
    "bandwagon_path_8 = 'human_bias/bandwagon/real/8.csv'\n",
    "bandwagon_path_9 = 'human_bias/bandwagon/real/9.csv'\n",
    "bandwagon_path_10 = 'human_bias/bandwagon/real/10.csv'\n",
    "bandwagon_path_11 = 'human_bias/bandwagon/real/11.csv'\n",
    "bandwagon_path_12 = 'human_bias/bandwagon/real/12.csv'\n",
    "bandwagon_path_13 = 'human_bias/bandwagon/real/13.csv'\n",
    "bandwagon_path_14 = 'human_bias/bandwagon/real/14.csv'\n",
    "bandwagon_path_15 = 'human_bias/bandwagon/real/15.csv'\n",
    "bandwagon_path_16 = 'human_bias/bandwagon/real/16.csv'\n",
    "bandwagon_path_17 = 'human_bias/bandwagon/real/17.csv'\n",
    "bandwagon_path_18 = 'human_bias/bandwagon/real/18.csv'\n",
    "bandwagon_path_19 = 'human_bias/bandwagon/real/19.csv'\n",
    "bandwagon_path_20 = 'human_bias/bandwagon/real/20.csv'\n",
    "bandwagon_path_21 = 'human_bias/bandwagon/real/21.csv'\n",
    "bandwagon_path_22 = 'human_bias/bandwagon/real/22.csv'\n",
    "bandwagon_path_23 = 'human_bias/bandwagon/real/23.csv'\n",
    "bandwagon_path_24 = 'human_bias/bandwagon/real/24.csv'\n",
    "bandwagon_path_25 = 'human_bias/bandwagon/real/25.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "distraction_path_1 = 'human_bias/distraction/real/1.csv'\n",
    "distraction_path_2 = 'human_bias/distraction/real/2.csv'\n",
    "distraction_path_3 = 'human_bias/distraction/real/3.csv'\n",
    "distraction_path_4 = 'human_bias/distraction/real/4.csv'\n",
    "distraction_path_5 = 'human_bias/distraction/real/5.csv'\n",
    "distraction_path_6 = 'human_bias/distraction/real/6.csv'\n",
    "distraction_path_7 = 'human_bias/distraction/real/7.csv'\n",
    "distraction_path_8 = 'human_bias/distraction/real/8.csv'\n",
    "distraction_path_9 = 'human_bias/distraction/real/9.csv'\n",
    "distraction_path_10 = 'human_bias/distraction/real/10.csv'\n",
    "distraction_path_11 = 'human_bias/distraction/real/11.csv'\n",
    "distraction_path_12 = 'human_bias/distraction/real/12.csv'\n",
    "distraction_path_13 = 'human_bias/distraction/real/13.csv'\n",
    "distraction_path_14 = 'human_bias/distraction/real/14.csv'\n",
    "distraction_path_15 = 'human_bias/distraction/real/15.csv'\n",
    "distraction_path_16 = 'human_bias/distraction/real/16.csv'\n",
    "distraction_path_17 = 'human_bias/distraction/real/17.csv'\n",
    "distraction_path_18 = 'human_bias/distraction/real/18.csv'\n",
    "distraction_path_19 = 'human_bias/distraction/real/19.csv'\n",
    "distraction_path_20 = 'human_bias/distraction/real/20.csv'\n",
    "distraction_path_21 = 'human_bias/distraction/real/21.csv'\n",
    "distraction_path_22 = 'human_bias/distraction/real/22.csv'\n",
    "distraction_path_23 = 'human_bias/distraction/real/23.csv'\n",
    "distraction_path_24 = 'human_bias/distraction/real/24.csv'\n",
    "distraction_path_25 = 'human_bias/distraction/real/25.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality Check & Filter Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_amt_to_df(batch_path):\n",
    "\n",
    "    d = pd.read_csv(batch_path)\n",
    "    d = d[['AssignmentId', 'WorkerId', 'Answer.taskAnswers', 'SubmitTime', 'WorkTimeInSeconds']]\n",
    "    d['WorkTime_min'] = d['WorkTimeInSeconds']/60\n",
    "    d = d[['AssignmentId', 'WorkerId', 'Answer.taskAnswers', 'SubmitTime','WorkTime_min']]\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AssignmentId</th>\n",
       "      <th>WorkerId</th>\n",
       "      <th>Answer.taskAnswers</th>\n",
       "      <th>SubmitTime</th>\n",
       "      <th>WorkTime_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34Z02EIMI23C6MK1QTGQ0998VI00T7</td>\n",
       "      <td>AG21SXBMQ4SK6</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>Tue Sep 26 20:27:46 PDT 2023</td>\n",
       "      <td>14.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3570Y55XZZ95YCUGE1SSTIO3H2EGYO</td>\n",
       "      <td>A2FNTIPS5UNJT5</td>\n",
       "      <td>[{\"task_1\":{\"A\":false,\"B\":true},\"task_10\":{\"A\"...</td>\n",
       "      <td>Tue Sep 26 22:24:29 PDT 2023</td>\n",
       "      <td>24.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39ZSFO5CAIMY850CC6G6NAA6D5TJU4</td>\n",
       "      <td>AZTAPCOD2Y512</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>Tue Sep 26 17:44:30 PDT 2023</td>\n",
       "      <td>10.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3KJYX6QCMJ1YLKPCHWQBJWCPRC2JVT</td>\n",
       "      <td>A1HU7PZ03ID3N9</td>\n",
       "      <td>[{\"task_1\":{\"A\":true,\"B\":false},\"task_10\":{\"A\"...</td>\n",
       "      <td>Tue Sep 26 17:57:58 PDT 2023</td>\n",
       "      <td>24.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3VELCLL3GU92U6NIRSF1XADH91F1FK</td>\n",
       "      <td>A2IK3H6MQ1QV6E</td>\n",
       "      <td>[{\"task_1\":{\"A\":false,\"B\":true},\"task_10\":{\"A\"...</td>\n",
       "      <td>Tue Sep 26 18:39:35 PDT 2023</td>\n",
       "      <td>65.633333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     AssignmentId        WorkerId   \n",
       "0  34Z02EIMI23C6MK1QTGQ0998VI00T7   AG21SXBMQ4SK6  \\\n",
       "1  3570Y55XZZ95YCUGE1SSTIO3H2EGYO  A2FNTIPS5UNJT5   \n",
       "2  39ZSFO5CAIMY850CC6G6NAA6D5TJU4   AZTAPCOD2Y512   \n",
       "3  3KJYX6QCMJ1YLKPCHWQBJWCPRC2JVT  A1HU7PZ03ID3N9   \n",
       "4  3VELCLL3GU92U6NIRSF1XADH91F1FK  A2IK3H6MQ1QV6E   \n",
       "\n",
       "                                  Answer.taskAnswers   \n",
       "0                                               [{}]  \\\n",
       "1  [{\"task_1\":{\"A\":false,\"B\":true},\"task_10\":{\"A\"...   \n",
       "2                                               [{}]   \n",
       "3  [{\"task_1\":{\"A\":true,\"B\":false},\"task_10\":{\"A\"...   \n",
       "4  [{\"task_1\":{\"A\":false,\"B\":true},\"task_10\":{\"A\"...   \n",
       "\n",
       "                     SubmitTime  WorkTime_min  \n",
       "0  Tue Sep 26 20:27:46 PDT 2023     14.416667  \n",
       "1  Tue Sep 26 22:24:29 PDT 2023     24.200000  \n",
       "2  Tue Sep 26 17:44:30 PDT 2023     10.550000  \n",
       "3  Tue Sep 26 17:57:58 PDT 2023     24.016667  \n",
       "4  Tue Sep 26 18:39:35 PDT 2023     65.633333  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_amt_to_df(distraction_path_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_invalid_data(order_path):\n",
    "\n",
    "    all_data = convert_amt_to_df(order_path)\n",
    "    raters_data = all_data['Answer.taskAnswers'].values\n",
    "    invalid_worker = []\n",
    "    invalid_worker_id = []\n",
    "\n",
    "    for i, rater in enumerate(raters_data):\n",
    "        rater_data = json.loads(rater)[0]\n",
    "        if (len(rater_data) != 0):\n",
    "            sorted_data = sorted(rater_data.items(), key=lambda x: int(x[0].split(\"_\")[1]))\n",
    "            for d, ratings in sorted_data:\n",
    "                if ratings == {'A': False, 'B': False}:\n",
    "                    print(f\"Didn't respond to questions: {all_data['WorkerId'][i]}\")\n",
    "                    print(f\"d: {d}, ratings: {ratings}\")\n",
    "                    invalid_worker.append(all_data['WorkerId'][i])\n",
    "                    invalid_worker_id.append(i)\n",
    "        else:\n",
    "            invalid_worker.append(all_data['WorkerId'][i])\n",
    "            invalid_worker_id.append(i)\n",
    "            print(f\"Nothing submitted: {all_data['WorkerId'][i]}\")\n",
    "    \n",
    "    return list(set(invalid_worker)), list(set(invalid_worker_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Order: 11\n",
    "- bandwagon: 10\n",
    "- distraction: 1, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing submitted: AG21SXBMQ4SK6\n",
      "Nothing submitted: AZTAPCOD2Y512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['AG21SXBMQ4SK6', 'AZTAPCOD2Y512'], [0, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_invalid_data(distraction_path_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_valid_data(amt_path):\n",
    "    amt_data = convert_amt_to_df(amt_path)['Answer.taskAnswers'].values\n",
    "    amt_worker_info = convert_amt_to_df(amt_path)['WorkerId'].values\n",
    "    _, invalid_workers_idx = check_invalid_data(amt_path)\n",
    "    valid_raters_data = np.delete(amt_data, invalid_workers_idx) \n",
    "    valid_raters_id = np.delete(amt_worker_info, invalid_workers_idx)\n",
    "\n",
    "    return valid_raters_data, valid_raters_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_valid_data(amt_path):\n",
    "\n",
    "    valid_raters_data, valid_raters_id = return_valid_data(amt_path)\n",
    "\n",
    "    for i, rater in enumerate(valid_raters_data):\n",
    "        print(f\"Rater idx: {i}, rater info: {valid_raters_id[i]} \")\n",
    "        rater_data = json.loads(rater)[0]\n",
    "        sorted_data = sorted(rater_data.items(), key=lambda x: int(x[0].split(\"_\")[1]))\n",
    "        rater_organized_data = {}\n",
    "        for task, ratings in sorted_data:\n",
    "            if ratings['A']:\n",
    "                rater_organized_data[task] = 'A'\n",
    "            elif ratings['B']:\n",
    "                rater_organized_data[task] = 'B'\n",
    "\n",
    "        print(rater_organized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_check_with_me(amt_path, me_path):\n",
    "\n",
    "    valid_raters_data, valid_raters_id = return_valid_data(amt_path)\n",
    "    with open(me_path, 'r') as me:\n",
    "        me_data = json.load(me)\n",
    "\n",
    "    for i, rater in enumerate(valid_raters_data):\n",
    "        print(f\"Rater idx: {i}, rater info: {valid_raters_id[i]} \")\n",
    "        rater_data = json.loads(rater)[0]\n",
    "        sorted_data = sorted(rater_data.items(), key=lambda x: int(x[0].split(\"_\")[1]))\n",
    "        rater_organized_data = {}\n",
    "        for task, ratings in sorted_data:\n",
    "            if ratings['A']:\n",
    "                rater_organized_data[task] = 'A'\n",
    "            elif ratings['B']:\n",
    "                rater_organized_data[task] = 'B'\n",
    "\n",
    "        \n",
    "        matching_tasks = sum(1 for key in me_data if me_data[key] == rater_organized_data[key])\n",
    "        perc_matching = (matching_tasks)/(len(me_data))\n",
    "        if perc_matching >= 0.5: \n",
    "            print(f\"Rater idx {i} passed 50% similarity, showing {round(perc_matching*100, 3)}%.\")\n",
    "        else:\n",
    "            print(f\"Rater idx {i} failed 50% similarity, showing {perc_matching*100}%.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = convert_amt_to_df(order_path_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.05"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.loc[d['WorkerId'] == 'A2E0LU8V4EUX5C']['WorkTime_min'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Participatation Time for Each Bias Exp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Didn't respond to questions: A1DL3O3MM8B5W\n",
      "d: task_30, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A3QDDYBRNDFRXX\n",
      "d: task_30, ratings: {'A': False, 'B': False}\n",
      "Nothing submitted: A3A27SMPYAYN8S\n",
      "Nothing submitted: A3APWAX21I89WB\n",
      "Nothing submitted: A2MLV78C8NBVTR\n",
      "Didn't respond to questions: A2D3G1Z5EH2V8N\n",
      "d: task_1, ratings: {'A': False, 'B': False}\n",
      "Nothing submitted: AQWZ3CVPB0HNU\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_1, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_2, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_3, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_4, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_5, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_6, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_7, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_8, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_9, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_10, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_11, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_12, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_13, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_14, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_15, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_16, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_17, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_18, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_19, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_20, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_21, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_22, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_23, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_24, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_25, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_26, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_27, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_28, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_29, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A165NK27A4EMG4\n",
      "d: task_30, ratings: {'A': False, 'B': False}\n",
      "Nothing submitted: AFK9ALQK5GPNG\n",
      "Nothing submitted: AHEK1Z46IHKNS\n",
      "avg:  47.84488888888891\n"
     ]
    }
   ],
   "source": [
    "order_time = []\n",
    "for i in range(1, 26):\n",
    "    path = f'order_path_{i}'\n",
    "    path_val = eval(path)\n",
    "    _, worker_ids = return_valid_data(path_val)\n",
    "    for worker in worker_ids:\n",
    "        d = convert_amt_to_df(path_val)\n",
    "        d_time = d.loc[d['WorkerId'] == worker]['WorkTime_min'].values[0]\n",
    "        order_time.append(d_time)\n",
    "\n",
    "print('avg: ', sum(order_time)/len(order_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing submitted: A184MZVD0VRQDP\n",
      "Nothing submitted: A1QO9CJ6KFDWQJ\n",
      "Didn't respond to questions: A13JJHDWBG4ZCM\n",
      "d: task_1, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A3D3FNUSK1A2P6\n",
      "d: task_1, ratings: {'A': False, 'B': False}\n",
      "Nothing submitted: A2M2HLOKLN7FP4\n",
      "Didn't respond to questions: A2F89G0V6F1F51\n",
      "d: task_30, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A1JDPMVFB8HNMH\n",
      "d: task_1, ratings: {'A': False, 'B': False}\n",
      "avg:  57.31888888888891\n"
     ]
    }
   ],
   "source": [
    "bandwagon_time = []\n",
    "for i in range(1, 26):\n",
    "    path = f'bandwagon_path_{i}'\n",
    "    path_val = eval(path)\n",
    "    _, worker_ids = return_valid_data(path_val)\n",
    "    for worker in worker_ids:\n",
    "        d = convert_amt_to_df(path_val)\n",
    "        d_time = d.loc[d['WorkerId'] == worker]['WorkTime_min'].values[0]\n",
    "        bandwagon_time.append(d_time)\n",
    "\n",
    "print('avg: ', sum(bandwagon_time)/len(bandwagon_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Didn't respond to questions: A1XRZRB8LA0ODQ\n",
      "d: task_30, ratings: {'A': False, 'B': False}\n",
      "Nothing submitted: A28LVKN22K756\n",
      "Didn't respond to questions: A3U5FZX51JBFQW\n",
      "d: task_26, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A3U5FZX51JBFQW\n",
      "d: task_27, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A3U5FZX51JBFQW\n",
      "d: task_28, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A3U5FZX51JBFQW\n",
      "d: task_29, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: A3U5FZX51JBFQW\n",
      "d: task_30, ratings: {'A': False, 'B': False}\n",
      "Nothing submitted: A9JDZK81AUKU3\n",
      "Nothing submitted: AG21SXBMQ4SK6\n",
      "Nothing submitted: AZTAPCOD2Y512\n",
      "Didn't respond to questions: A1MJVTR0PCKBWW\n",
      "d: task_30, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: ADTQZUNPMXKC6\n",
      "d: task_30, ratings: {'A': False, 'B': False}\n",
      "Didn't respond to questions: AQKRSW854ATWI\n",
      "d: task_30, ratings: {'A': False, 'B': False}\n",
      "Nothing submitted: A15C23AXOANKN2\n",
      "avg:  51.57844444444444\n"
     ]
    }
   ],
   "source": [
    "distraction_time = []\n",
    "for i in range(1, 26):\n",
    "    path = f'distraction_path_{i}'\n",
    "    path_val = eval(path)\n",
    "    _, worker_ids = return_valid_data(path_val)\n",
    "    for worker in worker_ids:\n",
    "        d = convert_amt_to_df(path_val)\n",
    "        d_time = d.loc[d['WorkerId'] == worker]['WorkTime_min'].values[0]\n",
    "        distraction_time.append(d_time)\n",
    "\n",
    "print('avg: ', sum(distraction_time)/len(distraction_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. IAA using RBO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `redpajama` and `dolly`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['gpt4', 'chatgpt', 'instructgpt', 'llama', 'cohere', 'falcon', 'alpaca', 'vicuna', 'openassist', \n",
    "               'baize', 'koala', 'wizardlm', 'mpt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_no_dolly_redpajama_indices(data): # for the real/...json file\n",
    "    excluded_values = [\"redpajama\", \"dolly\"]\n",
    "    indices = []\n",
    "    for i, item in enumerate(data):\n",
    "        if item[\"Model A\"] not in excluded_values or item[\"Model B\"] not in excluded_values:\n",
    "            indices.append(i)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_annotators_across_order(batch_i):\n",
    "\n",
    "    all_instructions_lst = []\n",
    "    agg_bias = {'first-order': [], 'last_order':[]}\n",
    "\n",
    "    # For each instruction, \n",
    "    # for batch_i in range(1, 26): \n",
    "    path_var_name = f'order_path_{batch_i}'  # Format the variable name\n",
    "    path_value = eval(path_var_name)   # Get the value of the variable\n",
    "    valid_raters_data, valid_raters_id = return_valid_data(path_value)\n",
    "\n",
    "    with open('human_bias/order/real/random_sampled_examples_order_{}.json'.format(batch_i), 'r') as j:\n",
    "        batch_json = json.load(j)\n",
    "\n",
    "    indices_no_dolly_redpajama = get_no_dolly_redpajama_indices(batch_json)\n",
    "\n",
    "    instruction_dict = {}\n",
    "\n",
    "    # For each rater (among 3),\n",
    "    for i, rater in enumerate(valid_raters_data):\n",
    "        rater_data = json.loads(rater)[0]\n",
    "        sorted_data = sorted(rater_data.items(), key=lambda x: int(x[0].split(\"_\")[1])) # (task 1 -> task 2 -> task 3 -> ); just re-ordering\n",
    "\n",
    "        rater_task_answer = {}\n",
    "        # Create a dictionary to store pairwise counts for each model\n",
    "        rater_organized_data = dict.fromkeys(model_names, 0)\n",
    "\n",
    "        # For each of 30 questions, count pairwise ranking\n",
    "        for task_idx, (task_name, ratings) in enumerate(sorted_data): # task_idx: 0, task_name: 'task_1', ratings: {'A':True, 'B':False}\n",
    "            if ratings['A']:\n",
    "                model_a = batch_json[task_idx]['Model A']\n",
    "                rater_organized_data[model_a] += 1\n",
    "                rater_task_answer[task_name] = 'A'\n",
    "\n",
    "            elif ratings['B']:\n",
    "                model_b = batch_json[task_idx]['Model B']\n",
    "                rater_organized_data[model_b] += 1\n",
    "                rater_task_answer[task_name] = 'B'\n",
    "\n",
    "        instruction_dict[i] = rater_organized_data\n",
    "\n",
    "        first_order = 0\n",
    "        last_order = 0\n",
    "\n",
    "        # For first-order or last-order bias, \n",
    "        for p in range(15):\n",
    "            all_pairs_idx = [instruct_idx for instruct_idx in range(len(batch_json)) if batch_json[instruct_idx]['pair_idx'] == p]\n",
    "            first_pair_idx = all_pairs_idx[0]\n",
    "            last_pair_idx = all_pairs_idx[1]  \n",
    "            print(f\"first: {first_pair_idx+1}, last: {last_pair_idx+1}\")\n",
    "            if (rater_task_answer['task_{}'.format(first_pair_idx+1)] == 'A') and (rater_task_answer['task_{}'.format(last_pair_idx+1)] == 'A'):\n",
    "                first_order += 1\n",
    "            else:\n",
    "                if (rater_task_answer['task_{}'.format(first_pair_idx+1)] == 'B') and (rater_task_answer['task_{}'.format(last_pair_idx+1)] == 'B'):\n",
    "                    last_order += 1\n",
    "        \n",
    "        agg_bias['first-order'].append(round(first_order/15, 3))\n",
    "        agg_bias['last_order'].append(round(last_order/15, 3))\n",
    "    \n",
    "    all_instructions_lst.append(instruction_dict)\n",
    "\n",
    "    return (all_instructions_lst, agg_bias)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLstudy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
